cours de réseaux MIF11

08/09

Généralités


Distribué : application s'éxécutant sur plusieurs noeuds; géographiquement éparpillé


Périphérie du réseau : tout ce qu'il y a autour : machines et utilisateurs

Réseau de coeur : ce qu'il y a au centre (opérateurs)

Réseau d'accès : lien intermédiaire entre le coeur et la périphérique (cable, fibre, etc)


Multiplexage  : inconvénient nécessité d'utiliser une intelligence supérieur
-Mauvaise utilisation des ressources (période d'inactivité)
-Etablissement connexion compliqué/couteux

Temps de transfert : 640 000 bits à envoyer

1536 000 bps / 24 = 64 000

640 000 bit / 64 000 bps= 10 s
+ 500 ms
10,5 s au total


Commuter : Paquet ou circuit ?
-Pour les appli en temps réels, avec contrainte fortes, privilégier CIRCUIT : De la ressource sera réservée pour l'utilisateur.
-Pour la simplicté et le coup de mise en place, privilégier PAQUET : 
-Pour le partage des ressources, privilégier PAQUET( pour l'opérateur/fournisseur) car permet plus d'utilisateurs simultanés, et CIRCUIT (pour l'utilisateur) car garantit à l'utilisateur une qtté de donnée.


Fragmentation des paquets :
L (taille du message en Mbits), C (bande passante en Mbps), n(nombre de saut) , m (nombre de paquets)
Sans Frag : 15 s (3 x 7.5 / 1.5) <=>  L * n /C
Avec fragmentation :7 s (3 x 7.5 / 5 / 1.5 + 4 x 7.5 /5 / 1.5) <=> n*L / m / C + (m-1)*L / m / C <=> temps d'attente du dernier paquet + temps de transfert.

Avantage : réduction du temps de transmission (RTT); perte uniquement du fragment perdu et non pas du message entier. Le transfert est parallélisé. Limite des erreurs grâce à la réduction de la taille des paquets.
Inconvénient : utilsation de davantage de ressource (multiplication des informations de transmission) rapport entete/donnée utile augmente; Désegmentation possible, donc réordonnancement.


Acheminement à la source :
Chaque paquet contient le chemin complet à suivre, avec les sorties des commutateurs sur la route.
Avantage : chemin emprunté connu, donc rapide
Inconvénient : Solution peu résistante aux changements de topologie; la taille de l'entete est variable et non bornée -> elle augmente proportionnellement avec la taille du chemin;


Acheminement par Circuit Virtuel :
On détermine un chemin entre la source et la destination : on attribue à chaque lien composant le chemin un identifiant de Circuit Virtuel. Un table de correspondance permet de lier
On change le numéro ID à chaque lien car : taille du champ réduite; gestion indépendante des commutateurs
Les commutateurs doivent répercuter les changements de topologie.


Avantage : moins de place; Qualité de Service QoS; Cout de l'entete bas; Acheminement rapide car chemin emprunté connu
Inconvénient : Attente avant établissement de la communication; si un lien tombe, besoin d'une nouvelle connexion.

Acheminement par Datagramme : 
Chaque paquet contient l'adresse de sa destination finale.
Avantage : pas d'attente avant la connexion; les paquets sont envoyés indépendemment de ceux des autres noeuds; Résistant aux changements de topologie;
Inconvénient : Sans connexion (pas de garantie sur la QoS; pas de garantie de livraison); les paquets sont envoyés indépendemment de ceux des autres noeux.


Réseau d'accès


Types de délais :
1 - Déali de traitement ~ns; délai constant (il est toujours présent)
2 - Délai d'attente (routeur) [0; ms]
3 - Délai de transmission [µs - ms] L/C si taille L sur un lien de bande passante C
4 - Délai de propagation ~[µs - ms] d/y si taille d du lien et vitesse de propagation y


Délai de bout en bout  = (N + 1) x (Dtrait + Dtrans + Dprop) + Somme des Dattente
OU (N+1) * 

Calcul numérique : Sans fragmentation = 15,3 s
				   Avec fragmentation = 7,3 s

Architecture en couche :
Avantages : Très modulable (possibilité d'évolution); Un protocole appartien à une couche (une seulement, normalement); identifier rapidement un aspect/service; changer l'implémentation d'une couche.
Inconvénient : Perte d'information liée à la communication aux couches adjacentes seulement. fonctions dupliquées; besoins de "cross-layer"


_________________________________________
Cours du 10/09/2014

La couche transport

Services de la couche Transport

-Les protocoles de transport : communication logique entre applis transport. Elle apparait uniquement sur les terminaux.
-Emetteur : divise les messages de taille variable (généralement gros) délivrés par des applis en segments( nom des paquets dans la couche transport), et les transmets à la couche transfert

(Récepteur : réassemble les segments en messages et les transmets à la couche Appli.

Plusieurs protocoles trsprts : UDP et TCP

Couche Appli & couche Trsprt :
-Faire communiquer plsieurs processus
-Via la socket (interface de connexion en fr)
	-API dominante sur les réseaux
	-modèle client serveur
	-au dessus de la couche trsprt


Couche réseau :
-de proche en proche, comm logique entre les noeuds (de saut en saut)

Couche Trsprt :
-comm logique entre les processus, opère de bout en bout.

La couche trsprt connait l'existence de la couche réseau : elle emet l'hypothèse qu'il existe un chemin (aucune garantie de performance)

Les protocoles de transport
-TCP : Livraison fiable (ordonnées, intactes) des données; controle de congestion; controle de flux;
-UDP : rien de tout ça.
-Truc commun : multiplexage et détection d'erreur.

Fiabilité /=/ détection d'erreur. Dire qu'il y a une erreur est différent de s'assurer du transfert des données.

TCP est utilisé en large majorité

Multiplexage : 
-Un chemin, plusieurs applications le parcourant => multiplexage logique.

Comment savoir à quelle appli appartiennent tels segments.
-Le multiplexage à l'emetteur rassemble les données des différentes sockets, les encapsuler, et les remets à la couche réseau. Le démultiplexage ouvre les messages et les transmets à la bonne socket.

Pour identifier à quelle appli correspond un segment TCP/UDP, on utilise les champs "port".
Un datagramme IP comporte une @IP Src et une @IP dest.
Les segments de la couche tsprt contiennent un #port src et un #port dest.

une socket UDP est identifiée par @IP dest et un #port src.

Plusieurs noeuds peuvent émettre vers une même socket (exemple d'un serveur multi client).

Les sockets TCP sont identifiés par les @IP src et dest et les #port src et dest.

UDP (RFC 768)
-service minimum de la couche trsprt
-sans connexion (pas d'échange, de négociation avec les couches tsprt du recepteur)

Avantages :plus rapide, car pas d'etablissement de connexion; Pas de connexion à maintenir; En-tête plus petite donc besoin en mémoire plus faible (8 octet contre 20 pour TCP);Meilleur contrôle de l'appli  sur l'émission : choix de la tille et de l'instant d'émission des segments.

Utilisé par des applications nécessitants une grande réactivité, comme DNS, SNMP, RIP, ou des applis multimédia tolérantes aux pertes (téléphonie par internet)

Somme de controle UDP : détecte les erreurs (bits altérés) dans les segments transmis


Principes d'un transfert de données fiable :
Comment construire un protocole de couche transport fiable sans pouvoir connaitre la fiabilité de la couche réseau, ou en la présumant non fiable.

rdt : reliable data transfert : données fiables, avec fnction receive et send
udt : unreliable data transfert : données non fiables, avec fonction receive et send

On va construire un protocole de trsfrt de donnée fiable, rdt xx (version)

Première version : on émet l'hypothèse que le canal est parfait : ni erreur ni perte.
-Coté expéditeur, on attend l'appel de l'appli, et on construit un packet (make paquet), qu'on envoie avec la fonction UDP. Une fois envoyé, on se remet en attente.
-Coté destinataire, on attend un appel de l'éméteur, on reçoit un paquet qu'on transmet à l'appli.

RDT 2.0, deuxième version : canal avec erreurs binaires -> le canal inférieur introduit des erreurs bits dans les paquets.
Pour rétablir ces erreurs :
-on les détecte
-on utilise un accusé de réception (ACK) qu'on attend pour s'assurer que le destinataire a bien reçu le paquet intact.NAK signifgie que le cpaquet reçu comporte une erreur.
-On retransmet les paquets corrompus/erronés.
->Send and Wait

-Coté émetteur : On attend les données de l'appli. On envoit un paquet, et on attend la réception de l'accusé de réception du destinataire. Si celles si étaient érronés, on les retransmet et on attend encore ACK ou NAK.
-Coté recepteur : On attend l'arrivée du paquet. Si il arrive corrompu, on envoie un NAK signifiant l'existence d'une erreur, sinon on envoie ACK à l'expéditeur. On transmet les paquets intacts à l'appli. Retour à l'attente.

rdt2.0 : si l'acquittement comporte une erreur : que faire?
On ne peut pas simplement ré-émettre, car une application réseau peut renvoyer plusieurs fois la même information, et le destinataire ne pourrait savoir s'il s'agit d'une retransmission ou d'un nouvel envoi.

Parades Possibles :
-Avertir d'une répétition, puis renvoyer (chiant à mettre en oeuvre, car nouveaux types de paquets)
-Ajouter un numéro de séquence dans le segment (solution adoptée par TCP)
->rdt2.1

On ajoute un numéro, si le numéro à déjà été reçu, on supprime le paquet.

Pour un protocole Send And Wait, on a besoin d'un seul bit. (pas dans ACK ni dans ACK)

Ce protocole est lourd : émetteur et récepteur doivent chacun vérifier ACK et NACK

-> On utilise un ACK au lieu d'un NACK : on renvoie l'ACK du dernier paquet bien reçu (le précédent si erreur dans le paquet courant) : deux fois le même ACK indique une erreur sur le dernier paque envoyé pour l'émetteur.

rdt 3.0 : canal avec erreur ET pertes
Erreur : paquet corrompu mais arrivé à destination
Perte : paquet jamais arrivé à destination.

On pourrait utiliser un temporisateur, mis en route après l'envoi du paquet : si il expire sans reception d'un ACK, on retransmet.
On va ajouter le numéro de séquence du paquet à acquitter.


Pièces maîtresses d'un protocole de trsprt de données fiables (rdt)
-Somme de contrôle (détection des erreurs)
-Accusés de réception (ACK & NACK), boucle de contrôle
-#séquence : détection des duplicata et des erreurs sur les ACK et pipeline
-"time"/temporisateur : pertes de paquets.

Performance de rdt 3.0
 1 Gbps -> C
 délai de propa : 15ms
 1 Ko -> L
 Ttransmiss : L/C : 8kb/1000 000Kbps : 8µs
 U :Utilisation du lien (pourcentage) = Transmiss/(Ttransmiss + 2 x dpropag) = 2.7 *10⁻⁴ ~= 30 ms
 Débit Utile : U * C = 266 596 bps = 267 Kbps.

 Inefficace.

 RTT : du premier bit transmis jusqu'a la réception du ACK (valeur temporelle)
 U = Ttransmiss/ RTT

 Protocoles pipelinés (à anticipation) : expéditeur peut transmettre plusieurs paquets à la suite, sans attendre d'accusés de réceptions.
 Fenêtre d'anticipation (YY): nbre de paquet possible à envoyer à la suite avant d'attendre les ack.
 Cela simule une parallélisation. Cela augmente l'utilisation., en multipliant ce dernier par la fenetre d'anticipation. La taille de la fenêtre se calcule aisni E [RTT/ Ttransmiss] + 1 . E étant la partie entière.

Le Pipeline, c'est très bien (meilleur utilisation des ressources réseaux), mais :
-L'ordre des paquets n'est plus garanti (désenquecement possible)
-Davantage de mémoire tampon utilisée
-Augmente la gamme de mémoire tampon.

Tampon de reséquencement : deux façons de faire :
-Répétition sélective : on garde les paquets arrivés dans le désordre et on attend d'avoir les paquets manquants pour transmettre dans l'ordre à la couche Appli.
-Go-Back N(Rejet simple) : On supprime le paquet arrivé dans le désordre et on attend de recevoir les paquets dans le bonne ordre

Le choix entre ces deux algos est guidés par la rareté des ressources bande passante(Répétition sélective) ou mémoire(Go Back N).


_ _ _ _ _ _ _ _ _ 
TCP : [RFC 793, 1122, 1323, 2018, 2581]
-Orienté connexion : échange d'information (handshaking); expéditeur et des fixent les params du trsfrt
-mode duplex :communicat° ds les deux sens
-Point-à-point : entre un expéditeur et un dest; 
-délivre des flux avec fiabilité et séquencement (tampons d'envois et de réception); MSS Maximum Segment Size (hors en tete)
-Pipeliné
-Contrôle de flux

Notion de Flux :
ensemble de données partant d'un emetteur vers un destinataire.

Flux TCP : Une connexion TCP entre deux noeuds
-Numéros de séquence exprimée en octet

Un segment de donnée comporte deux numéros :
-num de séquence : indique à la destination le positionnement du (premier octet du) paquet à l'intérieur du flux.
-#ACK numéro du prochain octet attendu

Le segment ACK comporte uniquement un numéro #ACK indiquand le prochain octet attendu.

Les acquttement (des segments et des acks) sont cumulatifs.

Exemple : pour un flux de 500 Ko avec un MSS de 1 Ko
On aura besoin de 500 segments
#séquence du 1er segment : 0 #ACK du ACK associé : 1000
#séquence du 2eme segment : 1000 #ack du ACK associé : 2000


RTT & RTO
RTT : round trip Time (temps de transmission aller retour.)

Comment fixer le RTO (Retransmission Time OUT)? en fonction du RTT. Mais si trop coourt, retransmission superflue, si trop long, réaction lente si segment perdu.

Comment estimer le RTT : sample RTT, tps mesuré entre la trsmssion du paquet et la réception du ack. On ignire les retransmissions : on lisse les valeurs des samplesRTT.

Génération des ACKs TCP :
Les ACKs sont des datagrammes : consomation de ressources.

Comment réduire leur impact.

Le traffic TCP se fait en raffale (un certain nombre de paquet à la suite) => Bursty, très actif un moment puis plus rien.

On retarde l'émission d'un acquittement d'un paquet pour voir si on ne reçoit pas un autre paquet ensuite, auquel cas on n'envoit un seul ACK qui remplace les deux.

Retransmission rapide : en cas de réception de trois ACKs identiques, alors on retransmet (sans que le timer n'ai expiré).

Contrôle de Flux : permet au destinataire de demander à l'expéditeur de ralentir sa vitesse d'émission/ de réduire son débit en réduisant sa fenetre d'anticipation.

_______________________________________________________________
Cours du 22/09/2014

Couche liaison de données :

CC le mercredi 8/10 de 11H45 à 12h15

Couche liaison de donnée, couche de niveau 2

Services et principes associés à cette couche

Vocabulaire : 
-noeud (tt élément du réseau),
-lien de communicaion (reliant des noeuds voisins), canal/medium de communication
-Trame -> paquet de donnée au niveau 2

Objectif du niveau 2 : assurer le trfrt de données entre deux ou plsrs voisins

Protocoles de liaison de données :
-Ethernet, PPP, FrameRelay, IEE 802.11(WiFi)
-Token (bus & Ring), HDLC

Ces différents protocoles peuvent fournir des services différents -> Certains services sont obligatoires pour tt protocole de la couche 2, d'autres sont facultatifs.

Ces protocoles sont implémentés dans un adaptateur (Network Interface Card) -> indépendantes, séparés des autres couches -> Mode semi-autonome.

Service de la couche 2 :
-Tramage : 
	-Encapsulation du datagramme ds une trame + champs supplémentaires (en-tête de niveau 2, informations sur la couche 2 , adresses MAC)
	-Assurer la communication entre deux noeuds voisins, réaliser les services de niveau 2.
	-Délimitation d'une trame  : fanion(bit), marqueur de de début et de fin (caractères)

En-tête dela couche 2 : 

-Détection d'erreur :
	-Erreurs possibles su le lien de communication (atténuation, bruits, collisions /interférences, Echo, Diaphonie)
	-Mécanisme réalisé au niveau hardware en général (optionnel)

Principe de la détection d'erreur : 
-Ajout de données de contrôle dans la trame par le noeud source (champs de détection d'erreur, checksum)
-Test de validité du paquet par le récepteur (utilisation du champs détection d'erreur par le récepteur : réponse soit positive, sans erreur, soit négative, avec erreur)
-Pas fiable à 100%, compromission sur la taille du champs détection d'erreur. Fiabilité dépendant aussi de la puissance du mécanisme de détection d'erreur.

Possibilité de faux positifs (erreurs s'annulant) et de faux négatifs

Premier mécanisme de détection d'erreur : bit de parité
-Avec un seul bit :
	-parité paire
	-parité impaire - Nbre de bit 1, bit de parité inclus, doit être impaire
	-détection simple
-Parité à deux dimensions
	-Détection de deux erreurs simultanées possible
	-Correction d'une erreur possible

Dans le monde IP, correction d'erreur dans la couche 3
-Somme sur les données : découpées en séquences continues de n bits, utilisée comme somme de contrôle
-Emetteur : donnée découpée en séquences de 16bits, complément à 1 de cette somme
-Récepteur : Somme sur les donnée reçues (sommes de contrôle incluses) => si que des un, c'est un succès.
-Utilisée sur les couches 3/4, mais pas sur la couche 2 :> protection faible, mais simple à réaliser -> utilisation duhardware au niveau 2, opérations plus compliquées permises.

CRC : Cyclic Redundancy Check
-D : Données à protéger
-G : générateur négocié entre la source et le destinateur, r bits à ajouter à D

Fiabilité :
-1 seule erreur tjrs détectée des que deux 1 dans G
-2 erreurs détectées dès que trois 1 ds G

Très utilisé, taille du générateur de 2 à 65 bits

récupération d'erreur  : 
-Si destinataire reçoit un paquet qu'il considère en erreur -> hypothèse de lien relativement fiable, et qu'en cas d'erreur, on peut retransmettre.
-Rejeter le paquet et ne rien faire d'autre -> les couches supérieures s'en occuperont (hypothèse)
-Prévenir la source qui peut éventuellement retransmettre -> envoi d'un ack lorsque qu'un paquet est reçu avec succès; ne rien faire en cas d'erreur. On attend que la source retransmette le paquet lorsque elle ne reçoit pas d'acquittement. Possiblité d'utiliser la fênetre glissante (plusieurs paquets à la fois).
-Corriger soi-même les erreurs (correction d'erreur) : possible avec l'utilisation de code correcteurs (code de Hamming), peu utilié en pratique au niveau de la couche 2. ->Utilisé au niveau 1

------------------------------------------------------
Types de lien de communication :
-unidirectionel : un seul sens
-bidirectionnel :
	-half-duplex : communication possible dans un seul sens à la fois
	-full duplex : communication simultanée possible.

Accès aux liens de communication
-lien pt à pt : seulement 2 stations connectées par ce médium (souvent full-duplex)
-lien partagé : plusieurs stations peuvent être connectés au lien; un paquet trsmis se propage vers ttes les stations

Protocole à accès multiple idéal :
-Hypothèse : médium partagé avec une capacité de D b/s
-Efficatié : Quand un noeud est seul à vouloir parler, il doit pouvoir utiliser tt le médium -> trsmettre à D b/s
-Équité : qd n noeuds veulent trmttre : le débit idéal serait de D/n b/s pour chaque station.
-Décentralisé (pas d'horloge, pas de coordinateur)

Classification (possible)
-Basé sur la notion de canal : découpage "strict" du médium de com en sous-parties (sous-canaux)

Techniques multicanaux :
-Time Division Multiple Acces : découpage en tmps, synchronisation nécessaire (sinon risque de collision si décalage)
-Frequency Division Multiple Acess : Découpage en fréquence ; débit éventuellement faible, diminuant avec le nbre de découpage.
-Code Division Multiple Access : utilisation de code => communications parallèles sur le lien partagé. Contrôle de puissance nécessaire. Le reste des signaux est négligeable/négligé.

Technique multicanaux :
-Marchent très bien quand le nbre d'utilisateur < à la bande passante/tps disponible (nbre de sous canaux)
-en général nbre de sous canaux << nbre d'utilisateur
-Sous canaux à trouver dynamiquement -> on demande à une entité spécifique pour obtenir un canal -> utilisation d'un protocole à accès aléatoire pour obtenir un sous canal

Protocole à accès aléatoire :
-Qd un noeud veut envoyer un pqt -> utilisation complète du médium, pas de coordination à priori entre les noeuds.
-Collision possible -> comment les détecter, comment les gérer?
-Exemples : types ALOHA, CSMA (CD/CA)

ALOHA : 
-Protocole à accès aléatoire developpé pour le 1 er réseau sans fil par commutation de pqt. Actuellement envoyés par le récepteur + retransmis de la source après un temps aléatoire si absence d'accusé de reception confirmant la réception du paquet par le destinataire.. -> Efficacité limitée 1/(2.E) de la capacité, diminuant avec le nbre de stations souhaitant trsmttre.
-Slotted ALOHA : efficacité doublé par les slots, nécessite une synchronisation. ->
-Les collisions sont gérées en faisant acquitter les émissions par le récepteur

Aloha slotté :
-même chose que l'Aloha, mais dans des slots
-performance doublée en terme de débit totale

Carrier Sens Multiple Acess CSMA : écoute du médium pour attendre sa libération avant d'envoyer. Reste des risques, en raison des tmps de propagation/trsmssion
-Collision Detection : la station qui transmet detecte une collision => arrêt de la com
	-lien filaire : comparaison entre le signal émis et le signal reçus, réalisée par les sources. Retrnsmssion après un tmps aléatoire. Les liens filaires sont assez fiables, pertes de pqts étant dus aux collisions/non acquittement des pqts bien rçus
	-Taille minimum sur les paquets pour détecter les collisions
	-signal de brouillage envoyé par les sources détectant une collision-> met toutes les stations du médium dans le même état -> repris ds Ethernet -> de - en - utilisé (Réseaux Ethernet Full-duplex.)
Algorithme csma !
	-SI on a un paquet dans l'interface réseau, on regarde le médium !
		-si le lien de communication est libre, alors on transmet
		-sinon, on attend que le lien soit libre, et alors on transmet le paquet
-En cas de collision.




-Collision Avoidance : sur un médium sans fil, difficile de faire du CD, donc paquets acquités par le destinataire. Si on est obligé d'attendre la fin d'une collision, c'est couteux en tmps. On essaye d'éviter au maximum les collisions à priori.
	-Tmps d'attente aléatoire avant la transmission du paquet d'un paquet (compromis entre le tmps d'attente et la réduction des collisions)
	-utilisé ds le wifi

Binary Exponential Backoff
-Fenêtre de contention (Contention Window)
Backoff : valeur entière aléatoire tirée dans la CW (0 à k). Le tirage se fait selon une distribution uniforme.
À chaque retransmission du paquet, on double la taille de la CW. On a donc une CMax et une Cmin.
On réinitialise la fenetre une fois que le paquet a bien été transmis

Protocoles sans collision



__________________________________________________________
Cours du 24/09/2014

Protocoles sans collision :
-protocoles sur invitation -> un "maître" invite les noeuds à parler; définie dans le WiFi, avec un protocole MAC, mais peut utilisé ou même implanté.
-Protocole à base de jeton : utilisé dans les réseau en anneaux; deux paquets => le msg et le jeton; le jeton circule, et les noeuds devant envoyer des msgs bloquent le jeton, trsmet le msg à la place, puis rend le jeton une fois assuré de la réception.

Prbs des protocoles sans collions :
-latence (tps d'attente parfois important pour pouvoir, soit obtenir la parole, soit obtenir le jeton)
-robustesse (risques augmentés avec l'importance du maître ou du jeton)

Résumé :
-Trammage (service de niveau 2)
-Détection d'erreur (optionnel, mais souvent utilisé)
-Récupération d'erreur (optionnel, utilisation de retransmission, d'acquitement (ACK), de BEB(espacement de retransmission)
-Protocole MAC


---------------------------------
Standardisation : IEEE, ISO, IETF

2 Technologies très utilisées
-Ethernet
-WiFi

Institue of Electrical and Electronics Engineers (1979) -> Developper des standards pour les couches 1 et 2 pour les réseaux locaux et métropolitains.
	Groupe 802 (février 1980) : contraintes initiales pour les réseaux locaux et métropolitains :
		-supporter 200 stations; Couverture entre 2 km (LAN) et 50 km (MAN); débit entre 1 et 100 Mb/s; insérer et retirer une stations sans perturbation; adressage individuel/en groupe

Adresse de niveaux 2 : @MAC, ne dépendant pas de la location
	-sur 48 bits, 3 octets attribués aux constructeurs de cartes, 3 octets correspondant au numéro de série.
	-Nouvelles adresse sur 64 bits
	-Adresse de diffusion : broadcast : FF-FF-FF-FF-FF-FF

WiFi : Wireless Fidelity -> IEE 802.11 => standardisation de pts d'accès pour les réseaux sns fil. Interopérabilité entre les différents constructeurs.

Réseaux sans fil
-Ondes électromagnétique ( < > 300GHz)
-Atténuation en fction de la distance et de la fréquence; réflexion perturbant la réception
-Si le SSB (signal sur Bruit) est supérieur à un certain seuil, elle décide de ne pas décoder.

Bande de fréquence des 2.4GHz : 
-divisé en 14 canaux de 20MHz, répartis sur 835 MHz
-Uniquement trois canaux indépendans spatialement
-Une communication entre deux stations se fait un canal.


Nous allons travailler sur la version 802.11b -> Les grds principes MAC sont les mêmes entre les différentes versions

Zones en WiFi :
-Zone de communication : ttes les machines se trouvant ds la zone de comm de la machine émetrice peuvent, si leur SNR est supérieur à leur seuil, décoder les msgs de la machine emetrice.
-Zone de détection de porteuse : ttes les machines ds cette zone considèrent le canal comme occupé, même si elles ne peuvent en décoder les paquets.
La taille de ces zones dépends de la modulation (couche physique). En effet, plus le débit/la modulation de transmission est grand(e), plus la porté de transmission est petite.

Étapes de l'Envoi d'un paquet. Accès au méidum en DCF, point à point
-Écoute du médium
-Si le médium est libre, tps d'attente éléatoire (Backoff) choisi dans une fenêtre de contention (CW).
-Le Backoff est décrémenté au fur et à mesure de chaque écoute, tant que le médium est libre. Quand il atteins 0, c'est le signale que la source peut-transmettre le paquet
-La source envoi le paquet
-Le récepteur reçoit correctement le paquet
-Acquittement positif envoyé par le destinataire
-SIFS => tps d'attente du récepteur avant envoi de l'ACK, plus court que le DIFS (tps d'attente de la source). Les acquittement sont privilégiés par rapport à l'envoi de paquet.

Si une source commence sa décrémentation de son Backoff, et que le medium est alors utilisé, la source garde la valeur du Backoff et le réutilisera quand le canal sera de nouveau libre (elle ne retire pas un nouveau Backoff aléatoire). Cela augmente les chances d'émission.
Et cela assure que tte station a sa chance.

seuil de RTS -> pour toutes les trames dont la taille est supérieur à ce seuil, RTS sera utilisé.

________________________________________________________________
Cours du 06/10

Partie essentielle de TCP : le contrôle de congestion

Pourquoi un contrôle de congestion ?
Un réseau, comme tt système physique, a des limites en matières de ressources : il peut travailler jusqu'a une certaine vitesse, et pas au dela. Cette vitesse est limitée par les composants et leurs caractéristiques.
Lorsque le traffic soumis augmente, quand l'ensemble de la charge dépasse ce que le réseau absorbe, on se retroouve en contention de ressources -> phénomène de congestion.

Idéalement : Si traffic utile soumis < Capacité réseau
	Traffic utile écoulé = traffic soumis
Sinon, au dela (Traffic utile soumis > Capacité réseau)
	Traffic utile écoulé = capacité réseau

En réalité, tt les réseaux ne fonctionnent pas comme ça. En effet, le cout des en-tête, l'utilisation des liens < 1, les erreurs de transmission, le dépassement de la capacité des buffers jouent sur le rapport données/données utiles. En raison de tout ces facteur, nous n'aurons pas un réseau fonctionnant idéalement.
L'un des objectif des recherches en réseau est d'éviter la zone d'effondrement de performance.

Exemples de réseau idéal :
-Tuyauterie 

Causes du comportement possible : cout protocoles et erreur de protocole
Exemple de réseau à courbe possible : Télésièges

Causes du comportement dit indésirable : collision et blocage
Exemple de réseau à comportement indésirable : aurotoutes.


Face à la congestion, deux solutions :
-retransmettre
-réguler les sources

Retransmettre est une très mauvais idée, cela ne fait qu'aggraver les choses.

2 approches possibles pour réguler les sources
-contrôle en boucle fermée, décisions indépendantes de l'état du réseau -> Peu utile, mais existante : surdimensionnement (consite à choisir des tecnologies résaux plus fortes de manières à ne pas rencontrer le problème, à s'éloigner de la zone de congestion); régulation de traffic/lissage (consite à rendre un traffic sporadique plus lisse, plus régulier, facilitant le transmission)
-Contrôle en boucle fermée, décisions basée sur des mécanismes de feedback : Plus utilisées plus adaptées ->
	-Contrôle d'admission : si une congestion est signalée, aucune nouvelle communication ne peut être établie
	-Pré-allocation des ressources : avant de démarrer la communication, chaque noeud sur la route réserve des ressources à cette communication. Plus adpaté à un réseau en mode connect, utilisation des ressources si la charges soumises est faible.
	-régulation isarythmique : limite le nbre de paquet en transit dans le réseau par un système de jetons, proche du mécanisme de TCP. Modifie la taille de la fenêtre d'anticipation pour réguler les sources; Mise en oeuvre difficile, avec le dimensionement du nbre de jetons, la répartitions, la circulation et l'intégrité des ressources
	-délestage : les routeurs submergés détruisent des paquets, avec un système de niveau de priorité pour détruire aussi peu de paquet que possible, et seulement des paquets de faible priorité.

Détecter une congestion : deux solutions
-Soit le réseau (les routeurs) informe les terminaux, avec un système de valeur.
-Soit les sources le font


Versions de TCP :
-> Détection de la congestion sans assistance du réseau, à partir des terminaux : ce sont les pertes de paquets qui permettent la détection de la congestion -> timeout, réception de 3 ACKs identiques = paquet perdu
-> Les pertes ne pas toujours liés à une congestion.
-> Réguler son débit : varier la fenêtre d'émission, cong_Fenetre dépend de l'état ressenti de congestion de réseau.
	En cas de congestion, on diminue la taille de la fenetre et par conséquent le nbre de paquet envoyés.
-> Pour un lien dédié d'une capacité C, le débit voulu pour la source sera C.
Pour un lien de capacité C partagé à plusieurs, le débit voulu par la source sea la bande passante résiduelle (disponible) ~= C - Traffic concurent. Problème, la bande passante résiduelle est dynamique et inconnue.

-> Détection de la bande passante disponible -> augmenter le débit TCP en agrandissant la taille de sa fenêtre de congestion jusqu'a atteindre le débit max supporté : comment savoir qu'on a atteint de débit max => des pertes se produisent.
Hausse addistive : augmenter la cong_Fenetre d'1 MSS après chaque RTT
Baisse multiplicative : divise la cong_Fenetre par 2
-> AIMD Additive increase Multiplicative Decrease

La courbe augmente linéairement jusqu'a l'apparition d'une perte; à ce moment la, division par deux de la taille de la fenêtre, puis augmentation linéaire de nouveau, et ainsi de suite. Traffic en dent de scie, avec évolution browniennede la taille des pics (dynamisme de la taille de la bande passante)

Le "slow start" de TCP :
-1 MSS = 500 octets, RTT = 200ms et W_{init} = 1MSS
-débit au premier RTT : 20 Kb.s⁻¹
-Débit au 2 eme RTT : 40 Kb.s⁻¹
-Débit au troisime RTT : 60 Kb.s⁻¹
-Débit à la première seconde : 40 Kb.s⁻¹

Or la bande passante disponible est souvent très largement supérieure : prb d'efficacité.
Solutions proposées : 
-augmentation de la valeur onitiale de cong_fenetre
-Augmenter exponentiellement le débit d'émission jusqu'a la première perte


Dans la réalité, le schéma en dent de scie décrit ci-dessus commence au départ non pas par une courbe linéaire, mais une courbe exponentielle. AInsi, le taux initial de transmission est faible mais sa croissance exponentielle

Distinction sur le type de perte :
-Si arrivée de 3 ACKs identique, cong_fenetre div 2 et croissance linéraire -> réseau encore capble de transmettre
-Si timeout, cong_fenetre fixé à 1 MSS et croissance exponentielle -> scénario plus alarmant.

Le débit moyen (à long terme)
-> Approximation classisque (sans tenir compte du "slow start")
-> pour une fenetre de la taille w, débit instantané w/RTT

W la taille de la fenêtre à l'instant de perte
	·cong_Fenetre évolue entre 0.5W et W
	·le débit d'émission augmente linéairement entre 0.5W / W et W/RTT
		=> débit moyen  ~= 0.75×W/RTT

	Le débit moyen ~= \frac{1.22MSS}{RTT\sqrt{Pr}} avec Pr le taux de perte

Les flux avec les petits RTT sont plus "agressifs" vis à vis des autres flux
-> pas adpaté aux réseaux très haut-débits
-> Pas adapté aux réseaux sans fil
	·Risque de surréaction aux évenements de la couche 2
	·BER ou collisions (pertes couche 2) du au média radio
	·retardent les paquets -> déclenchent Timeout
	·pas forcement une congestion du réseau
->Le débit TCP n'est pas décidé par l'application
->Pourquoi ne pas utiliser UDP? -> perte des services proposé par TCP
-> UDP se base sur des estimations du débit moyens de TCP

----------------------------------------------------------
La couche réseau

Pourquoi router? Qu'est ce que router?
On ne peut pas relier ts les noeuds entre eux. Ce n'est pas réalisable.

On utilise un réseau à maillage. Tt le problème du routage sera de COMMENT router des informations d'un noeud à un autre.

Trois façons de distribuer une info dans un réseau
-unicast : une source vers un destinataire
-broadcast : un noeud vers tt le monde (envoie d'une copie a tt les noeuds, multiplication des copies des paquets)
-multicast : un noeud vers une liste fermée de noeuds, un ensemble de noeud

La couche réseau, contrairement à la couche trsport, opére sur quasiment tt les noeuds.
Le rôle de la couche réseau est de permettre le trsport des segments de l'expérditeur au destinataire :
-encapsule les segments dans des datagramm chez l'expéditeur
-délivre les segments à la couche trsprt chez le destinataire

Service de la couche réseau : 
-Nommage : donne un nom, un identifiant logique d'une unité -> indépendant de la topologie, ne peut être utilisé pour router.
-Adressage : identifiant topologique d'une entité, dépendant de la position dans le réseau, utilisé pour router, doit être en principe unique (@IP)
-Dissémination : divulgation de la paire nom/adresse (DNS) => chainon manquant entre les noms connus et les @IP.
-Acheminement/réexpédition : trsfrt d'un paquet d'une interface d'entrée d'un routeur à l'unde des sorties ("forwarding")
-Routage : déterminer la route de bout-en-bout à suivre par le paquet depuis la source jusqu'a la destinat°, algortihme de routage
-Établissement d'une connexion virtuelle (pas toujours, voir très rarement) : précède l'envoi des donnée, implique les temrinaux et routeurs connectés.

Distinction acheminement - routage
Le routeur interroge les tables d'acheminement local (table de routage) qui sont construite à partir des algorithmes de routage.

Il n'existe que IP en couche 3. IP est un algo du best effort : pas de garantie sur le débit, sur les pertes, sur le séquencement des données ou leur ordre d'arrivée, ou sur le délai. Le role d'IP a été réduit au strict minimum.

-Réseau à datagramme : service réseau sans connexion
-Réseau à circuit virtuel : orienté connexion

Chemin de la source à la destination = circuit virtuel, a la manière du réseau téléphonique.

Si on doit établir une comm, il faut faire un aller retour.
Avec un réseau à datagramme, pas d'établissement de connexion. Les paquets ne sont pas forcément transmis sur le meme chemin, tandis que dans un circuit virtuel, le chemin est défini et tous les paquets l'empruntent

Environ quatre milliard d'@IP
Aucune table de cette, taille, donc on fait de l'aggrégation d'adresse : on regroupe les @ comprises dans une même intervalle, puisque les @ ont un sens topologique (elles sont sensés être proche si elles se suivent.

Réseaux à datagrammes :
-Algorithme : comment choisit t'on la ligne qui nous intéresse? En comparant les lignes avec l'adresse désiré. Mais il peut y avoir des ambiguités, quand plusieurs lignes correspondent à l'adresses souhaité. On choisit alors la ligne avec le préfixe partagé le plus long.

Le protocole IP est implémenté sur ts les noeuds (utilisateurs, routeurs)

Format d'un datgramme
-En-tete de 40 octets : 20 TCP + 20 IP
-Version : version d'IP (IPV4 pour nous, autre possibilité IPV6)
-Hlen : indique la taille de l'en-tête
-ToS : Type of Service, indique la façon dont le paquet doit être traité (QoS)
-Total Length : exprimé en nbre d'octet, comprend l'en tête, codé sur 16 bits (taille max du paquet : 2¹⁶ = 65 535 octets)
-TTL : Time To Live, fixe une durée de vie maximale pour un paquet, exprimée en nbre de saut, décrémentant à chaque routeur/noeud rencontré. Le paquet est supprimé quand il arrive à zéro. Permet d'éviter qu'un paquet tourne indéfiniment dans le réseau (par exemple en présence d'une boucle de routage)
-Protocol
-Checksum : somme de contrôle, détectant les erreurs de trsfert, calculé sur l'entête seulement, complément à 1 de la somme de l'entête
-les @IP codées sur 32 bits chacunes
-Les options (inutilées)

Les couches physiques sont très hétérogènes. Chaque liaison a une valeur de MTU (maximum transmission Unit). Que faire lorsque la taille du datagramme > MTU?
Avec IPV4, si le paquet est trop gros, il le fragmente.

_________________________________________________________
Cours du 15/10

L'adressage IP

Une @ IP sert à identifier un noeud, une interface
Les interfaces (connexion entre l'hote/routeur et le lien physique) ont chacune leur propres @IP, même sur un même hote/routeur

Composition d'une @ IP:
-Composante réseau (bits de poids fort, deux premiers octets)
-composante hôte (bits de poids faible)

Sous réseau : ensemble d'interface ayant leur composante réseau commune (elles n'ont pas besoin de routeurs pour communiquer entre elles)

Les classes A, B et C de sous-réseaux sont désormais obsolètes : 
maintenant, choix libre pour la longueur de la partie réseau de l'adresse
Format d'une adresse : a.b.c.d/x avec x le masque de sous réseau, le nbre de bit de la composante réseau.

Obtention de l'@ IP :
-manuelle (configuration via un fichier ou des propriétés)
-automatique (obtention dynamique de l'@IP via le DHCP (Dynamic Host Configuration Protocol)

Les réseaux obtiennent leurs adresses IP via les FAI

Adressage hiérachique : annonciation efficace des informations de routages; utilisation d'agrégation de routes
Possibilité d'utiliser une route spécifique dans les cas d'entrées individuelles (les algos de routages prennent les blocs dont la composante réseau est la plus longue.

Comment les FAI obtiennent les blocs d'@ ?
-Ils demandent à l'ICANN Internet Corporation for Assigned Names and Numbers, qui gèrent les @ IP, le DNS.

Classes d'@ privées, destinées aux réseaux locaux (pas de paquets sur Internet avec ces @ IP, ils sont confinés aux réseaux locaux).


NAT : Network @ Translation

Transformer une @ IP locale (non routable) en @ IP routable sur internet (publique). Les datagrammes circulant sur le réseau local ont une @ IP locale, dès qu'ils sortent du réseau local, ils ont l'@ IP publique du routeur.
Vis à vis de l'extérieur, les réseaux locaux n'utilisent qu'une @ IP (quelque soit le nbre différente). Cela permet d'économiser des @ publiques (on adresse plusieurs machines avec une @). Possibilité de changer de FAI sans changer l'@IP des machines locales. Et vis à vis de l'extérieur, personne ne connait les machines du réseau local

Le routeur NAT remplace dans les datagrammes sortant les @IP src et le N° de port src par l'@NAT et un nouveau n° de port.
Il y a environs 60 000 connexions simultanées disponibles derrière une seule @ IP
L'utilisation intensive du NAT est controversée, car les routeurs ne devaient pas agir au delà de la couche 3(aors qu'on attaque la couche 4), que le NAT rompt le principe de bout en bout de la couche transport. La possibilité d'un NAT doit être pris en compte par les developpeurs (P2P, IPsec, FTP active mode)

Un routeur classique modifira possiblement les champs ToS, Total length, Flags, Frag Offset, TTL, Checksum (les deux derniers forcément) de l'en-tête IP
Le routeur NAT modifie ces mêmes champs, plus les @IP destinations et sources, les n° de ports sources et destination, ainsi que la checksum, mais cette fois ci de la couche 4 (TCP)

ICMP : envoyer des informations au niveau réseau entre les noeuds, notemment pour les erreurs, les pings et le traceroute (chemin parcouru par les pquets vers une destination).

------------------------
Algorithmes de routages

Deux familles d'algorithmes :
-algo centralisés (chaque noeud a une connaissance complète du réseau) -> algo par états de lien
-algo décentralisés (chaque noeud connait uniquement ses voisins et le cout de ces liens) -> algo à vecteur de distance

Algo de dijkstra

Complexité de l'algorithme pour un réseau de n noeuds
- à chaque itération, tester tous les noeuds à l'extérieur de N
- car{N} incrémente de 1 jusqu'a N
- donc (N(n+1)/2 comparaison : o(n²)
- o(nlog(n)) avec une implémentation efficace

Routage par vecteur de distance :

