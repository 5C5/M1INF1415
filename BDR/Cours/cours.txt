Cours de Base de données Réparties et Déductives

Cours du 09/0

Notions :
-Contention : ressource partagée entre plusieurs utilisateurs
-passage à l'échelle : partage d'un nbre important de données entre un nbre très important d'utilisateurs.

-Utilisation de plusieurs bases en réseau, améliorant la disponibilité de données, la répartition de la charge, et facilitant la gestion locale

-Base de données réparties : système gérant de manière transparente un ensemble de BD logiquement reliées et réparties sur différents sites -> Solution reposant sur un schéma global
	->Système homogènes

-> Contexte de données hétérogènes.
	->Base de données Fédérées : Système gérant plusieurs BD hétérogènes capables d'interopérer via un modèle commun -> On se met d'accord sur une vue commune pour interroger les données

	-Dans le cas ou certaines données n'exploitent pas la puissance d'un SGBD (fichier texte, autre). Nécessité d'utiliser une surcouche logicielle(médiateur, wrappeur) pour palier

-Architecture de médiation : Système gérant plusieurs sources de données hétérogènes capables d'interopérer via une architecture de médiation (Via un langage pivot)

Centralisée -> Distribué (Fédéré, médiation)


·Passage à l'échelle
-Système multi-Base : système gérant plusieurs ND (hétérogène ou non) capables d'interopérer sans modèle commun.


Problème : Comment offrir aux utilisateurs une vue sur l'ensemble des données en faisant abstraction de leur localisation physique en garantissant de bonnes performances de traitement de requêtes (tps de traitement, passage à l'échelle).

Fin de l'introduction
----------------------------------------------------------------
Pré-requis : Algèbre relationnelle
	Def : une lagèbre relationnele est un ensemble d'opérations agissant sur des relations et produisant des relations. Langage fermé
	Opérateurs : Union, intersection, Difference, Produit Carthésien, Projection, Sélection, Jointure, Semi-Jointure, Renommage


Scenarii possibles :
-Données centralisées -> doivent être répartie sur différents sites (comment découper logiquement)
-Données réparties -> doivent être interrogeables depuis n'importe quel site(comment offrir un moyen d'accès transparent à ces données)

·Premier scénario
	-Dans un contexte centralisé, Analyse des données, Conception du modèle conceptuel, Conception du modèle logique
	-Dans un contexte décentralisé, même chose que ci-dessus, puis processus de distribution : Migration/Décomposition/Réplication, Allocation/Placement

	Le schéma global est constitué d'un schéma conceptuel global (contenant la description glob et unifiée de toutes les données de la BDR, indépendant de la répartition des données) et d'un schéma de placement/allocation(contenant lkes règles de correspondances avec les données locales)


-La migration : Transfert de données d'une base source sur une base cible (Copie puis suppression source), permet de rapprocher les données

-La réplication : Création d'une copie conforme des données -> copies secondaires (Copie, puis synchronisation pour garder les mêmes données sur les 2 sites). Permet d'avoir les mêmes données sur différents sites

-La décomposition : Fragmenter, décomposer la base initiale en fragments, qui sont répartis, alloués à différentes bases

Les différentes fragmentations :
	-fragmentations horizontale 		-> sélection d'un ensemble de tuples
	-fragmentation horizontale dérivée	-> sélection dépendant d'un fragment
	-fragmentaton verticale				-> projection sur un ensemble d'attributs
	-frag mixte

/!\ Pour les fragmentions verticales, obligations de s'assurer que la clé primaire appartient à chacun des fragments

-Si R=(A1, ..., Ak) la table originale, la fragmentation est dite correcte si elle est :
	-complète (chaque élément de R se retrouve dans un fragment)
	-reconstructible (R doit pouvoir être recomposer depuis ses fragments)
	-disjointe (chaque élément de R (hormis les clés) ne doit pas être dupliqué (present plusieurs fois)



Fragmentation horizontale ≃ Sharding (permet le stockage et l'indexation de grandes masses de données)
	Intéret : ttes les données ne peuvent être stockés sur un seul serveur; La capacité en mémoire du serveur ne perment pas de garantir un service satisfaisant; Le volume de m-à-j de données est trop important


Méthodlogies :
stratégies de fragmentation :
	-en fction des hypothèses (informations sur les contraintes de placement)
	
	-en fction des besoins (Informations sur les requêtres généralement posées)


Réplication :
-Principe : créer des copiées conformes aux tables sur des sites distants se synchronisant en fct° des m-à-j
	->Améliore la disponibilité des données en local
	-> est avantageux si il y a plus de lectures que d'écriture

	-Fonctions d'un réplicateur :
		·def des objets répliqués
		·def de la fréquence de rafraichissement(immédiat, à intervalle régulier, à partir d'un évennement)
		·Rafraichissement(complet/partiel, push(primaire->secondaire)/pull(secondaires->primaire)).

	-Gestion partagée des maj des répliques : une donnée appartient à plusieurs sites qui peuvent chacun mettre à jour et modifier.

	Détection des modifications (pour le rafraichissement)
		-solution 1 : utilisation d'un journal (transactions modifiantes marquent le journal, détection périodique ds le journal, indépendemment de la transac, modif de la gest° du journal)
		-solution 2 : utilisation de triggers (de - en - utilisés)


CREATE DATABASE LINK <nom> CONNECT TO <loginUser> IDENTIFIED BY <psswd> USING <orapeda1|orapeda2|orapeda3>
CREATE MATERIALIZED VIEW <nom> REFRESH {on commit| on demand| start with ... next ...][complete}
